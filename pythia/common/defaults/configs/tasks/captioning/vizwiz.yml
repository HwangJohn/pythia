task_attributes:
    captioning:
        datasets:
        - vizwiz
        dataset_size_proportional_sampling: true
        dataset_attributes:
            vizwiz:
                data_root_dir: data
                image_depth_first: false
                fast_read: false
                image_features:
                    train:
                    - vizwiz/train_npy
                    val:
                    - vizwiz/val_npy
                    test:
                    - vizwiz/test_npy
                imdb_files:
                    train:
                    - imdb/coco_captions/imdb_karpathy_train.npy
                    val:
                    - imdb/coco_captions/imdb_karpathy_val.npy
                    test:
                    - imdb/coco_captions/imdb_karpathy_test.npy
                features_max_len: 100
                processors:
                  text_processor:
                    type: vocab
                    params:
                      max_length: 52
                      vocab:
                        type: intersected
                        embedding_name: glove.6B.300d
                        vocab_file: vocabs/vocabulary_captioning_thresh5.txt
                      preprocessor:
                        type: simple_sentence
                        params: {}
                  caption_processor:
                    type: caption
                    params:
                      vocab:
                        type: intersected
                        embedding_name: glove.6B.300d
                        vocab_file: vocabs/vocabulary_captioning_thresh5.txt
                min_captions_per_img: 5
                return_info: false
                # Return OCR information
                use_ocr: false
                # Return spatial information of OCR tokens if present
                use_ocr_info: false
training_parameters:
    monitored_metric: coco_caption_bleu4
    metric_minimize: false
