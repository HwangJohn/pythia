{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import easydict\n",
    "from pprint import pprint\n",
    "from pythia.trainers.base_trainer import BaseTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "import glob\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "from pythia.common.registry import registry\n",
    "from pythia.utils.build_utils import build_trainer\n",
    "from pythia.utils.distributed_utils import is_main_process\n",
    "from pythia.utils.flags import flags\n",
    "\n",
    "\n",
    "def setup_imports():\n",
    "    # Automatically load all of the modules, so that\n",
    "    # they register with registry\n",
    "    root_folder = registry.get(\"pythia_root\", no_warning=True)\n",
    "\n",
    "    if root_folder is None:\n",
    "        #         root_folder = os.path.dirname(os.path.abspath(__file__))\n",
    "        root_folder = os.path.dirname(os.getcwd())\n",
    "        root_folder = os.path.join(root_folder, \"..\")\n",
    "\n",
    "        environment_pythia_path = os.environ.get(\"PYTHIA_PATH\")\n",
    "\n",
    "        if environment_pythia_path is not None:\n",
    "            root_folder = environment_pythia_path\n",
    "\n",
    "        root_folder = os.path.join(root_folder, \"pythia\")\n",
    "        registry.register(\"pythia_path\", root_folder)\n",
    "\n",
    "    trainer_folder = os.path.join(root_folder, \"trainers\")\n",
    "    trainer_pattern = os.path.join(trainer_folder, \"**\", \"*.py\")\n",
    "    tasks_folder = os.path.join(root_folder, \"tasks\")\n",
    "    tasks_pattern = os.path.join(tasks_folder, \"**\", \"*.py\")\n",
    "    model_folder = os.path.join(root_folder, \"models\")\n",
    "    model_pattern = os.path.join(model_folder, \"**\", \"*.py\")\n",
    "\n",
    "    importlib.import_module(\"pythia.common.meter\")\n",
    "\n",
    "    files = glob.glob(tasks_pattern, recursive=True) + \\\n",
    "            glob.glob(model_pattern, recursive=True) + \\\n",
    "            glob.glob(trainer_pattern, recursive=True)\n",
    "\n",
    "    for f in files:\n",
    "        if f.endswith(\"task.py\"):\n",
    "            splits = f.split(os.sep)\n",
    "            task_name = splits[-2]\n",
    "            if task_name == \"tasks\":\n",
    "                continue\n",
    "            file_name = splits[-1]\n",
    "            module_name = file_name[: file_name.find(\".py\")]\n",
    "            importlib.import_module(\"pythia.tasks.\" + task_name + \".\" + module_name)\n",
    "        elif f.find(\"models\") != -1:\n",
    "            splits = f.split(os.sep)\n",
    "            file_name = splits[-1]\n",
    "            module_name = file_name[: file_name.find(\".py\")]\n",
    "            importlib.import_module(\"pythia.models.\" + module_name)\n",
    "        elif f.find(\"trainer\") != -1:\n",
    "            splits = f.split(os.sep)\n",
    "            file_name = splits[-1]\n",
    "            module_name = file_name[: file_name.find(\".py\")]\n",
    "            importlib.import_module(\"pythia.trainers.\" + module_name)\n",
    "        elif f.endswith(\"builder.py\"):\n",
    "            splits = f.split(os.sep)\n",
    "            task_name = splits[-3]\n",
    "            dataset_name = splits[-2]\n",
    "            if task_name == \"tasks\" or dataset_name == \"tasks\":\n",
    "                continue\n",
    "            file_name = splits[-1]\n",
    "            module_name = file_name[: file_name.find(\".py\")]\n",
    "            importlib.import_module(\n",
    "                \"pythia.tasks.\" + task_name + \".\" + dataset_name + \".\" + module_name\n",
    "            )\n",
    "\n",
    "\n",
    "# def run():\n",
    "#     setup_imports()\n",
    "#     parser = flags.get_parser()\n",
    "#     args = parser.parse_args()\n",
    "#     trainer = build_trainer(args)\n",
    "\n",
    "#     # Log any errors that occur to log file\n",
    "#     try:\n",
    "#         trainer.load()\n",
    "#         trainer.train()\n",
    "#     except Exception as e:\n",
    "#         writer = getattr(trainer, \"writer\", None)\n",
    "\n",
    "#         if writer is not None:\n",
    "#             writer.write(e, \"error\", donot_print=True)\n",
    "#         if is_main_process():\n",
    "#             raise\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_imports()\n",
    "parser = flags.get_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python tools/run.py --tasks captioning --datasets coco --model butd  --config configs/captioning/coco/my_butd_local.yml \n",
    "args = parser.parse_args(args=['--tasks', 'captioning', '--datasets', 'coco', '--model', 'butd', '--config', 'configs/captioning/coco/my_butd_local.yml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "includes:\r\n",
      "- common/defaults/configs/tasks/captioning/coco.yml\r\n",
      "model_attributes:\r\n",
      "  butd: &butd\r\n",
      "    model_data_dir: data/\r\n",
      "    metrics:\r\n",
      "    - type: caption_bleu4\r\n",
      "    losses:\r\n",
      "    - type: caption_cross_entropy\r\n",
      "    classifier:\r\n",
      "      type: language_decoder\r\n",
      "      params:\r\n",
      "        dropout: 0.5\r\n",
      "        hidden_dim: 1024\r\n",
      "        feature_dim: 2048\r\n",
      "        fc_bias_init: 0\r\n",
      "    image_feature_embeddings:\r\n",
      "    - modal_combine:\r\n",
      "        type: top_down_attention_lstm\r\n",
      "        params:\r\n",
      "          dropout: 0.5\r\n",
      "          hidden_dim: 1024\r\n",
      "          attention_dim: 1024\r\n",
      "      normalization: softmax\r\n",
      "      transform:\r\n",
      "        type: linear\r\n",
      "        params:\r\n",
      "          out_dim: 1\r\n",
      "    image_feature_dim: 2048\r\n",
      "    embedding_dim: 300\r\n",
      "    image_feature_encodings:\r\n",
      "    - type: finetune_faster_rcnn_fpn_fc7\r\n",
      "      params:\r\n",
      "        bias_file: detectron/fc6/fc7_b.pkl\r\n",
      "        weights_file: detectron/fc6/fc7_w.pkl\r\n",
      "    inference:\r\n",
      "      type: greedy\r\n",
      "optimizer_attributes:\r\n",
      "  type: Adamax\r\n",
      "  params:\r\n",
      "    eps: 1.0e-08\r\n",
      "    lr: 0.01\r\n",
      "    weight_decay: 0\r\n",
      "training_parameters:\r\n",
      "  clip_norm_mode: all\r\n",
      "  clip_gradients: true\r\n",
      "  lr_ratio: 0.1\r\n",
      "  lr_scheduler: true\r\n",
      "  lr_steps:\r\n",
      "  - 1\r\n",
      "  - 1\r\n",
      "  - 1\r\n",
      "  - 1\r\n",
      "  max_grad_l2_norm: 0.25\r\n",
      "  max_iterations: 1\r\n",
      "  use_warmup: true\r\n",
      "  warmup_factor: 0.2\r\n",
      "  warmup_iterations: 1000\r\n",
      "  patience: 1\r\n",
      "  batch_size: 2\r\n",
      "  num_workers: 0\r\n",
      "  task_size_proportional_sampling: true\r\n",
      "  monitored_metric: caption_bleu4\r\n",
      "  metric_minimize: false\r\n",
      "  data_parallel: true\r\n"
     ]
    }
   ],
   "source": [
    "!cat configs/captioning/coco/my_butd_local.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = build_trainer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to: ./save/captioning_coco_butd/logs/captioning_coco_butd_2020-03-19T10:43:03.log\n",
      "2020-03-19T10:43:03 INFO: =====  Training Parameters    =====\n",
      "2020-03-19T10:43:03 INFO: {\n",
      "    \"batch_size\": 2,\n",
      "    \"clip_gradients\": true,\n",
      "    \"clip_norm_mode\": \"all\",\n",
      "    \"data_parallel\": true,\n",
      "    \"device\": \"cuda\",\n",
      "    \"distributed\": false,\n",
      "    \"evalai_inference\": false,\n",
      "    \"experiment_name\": \"run\",\n",
      "    \"load_pretrained\": false,\n",
      "    \"local_rank\": null,\n",
      "    \"log_dir\": \"./logs\",\n",
      "    \"log_interval\": 100,\n",
      "    \"logger_level\": \"info\",\n",
      "    \"lr_ratio\": 0.1,\n",
      "    \"lr_scheduler\": true,\n",
      "    \"lr_steps\": [\n",
      "        1,\n",
      "        1,\n",
      "        1,\n",
      "        1\n",
      "    ],\n",
      "    \"max_epochs\": null,\n",
      "    \"max_grad_l2_norm\": 0.25,\n",
      "    \"max_iterations\": 1,\n",
      "    \"metric_minimize\": false,\n",
      "    \"monitored_metric\": \"caption_bleu4\",\n",
      "    \"num_workers\": 0,\n",
      "    \"patience\": 1,\n",
      "    \"pin_memory\": false,\n",
      "    \"pretrained_mapping\": {},\n",
      "    \"resume\": false,\n",
      "    \"resume_file\": null,\n",
      "    \"run_type\": \"train+inference\",\n",
      "    \"save_dir\": \"./save\",\n",
      "    \"seed\": null,\n",
      "    \"should_early_stop\": false,\n",
      "    \"should_not_log\": false,\n",
      "    \"snapshot_interval\": 1000,\n",
      "    \"task_size_proportional_sampling\": true,\n",
      "    \"trainer\": \"base_trainer\",\n",
      "    \"use_warmup\": true,\n",
      "    \"verbose_dump\": false,\n",
      "    \"warmup_factor\": 0.2,\n",
      "    \"warmup_iterations\": 1000\n",
      "}\n",
      "2020-03-19T10:43:03 INFO: ======  Task Attributes  ======\n",
      "2020-03-19T10:43:03 INFO: ======== captioning/coco =======\n",
      "2020-03-19T10:43:03 INFO: {\n",
      "    \"data_root_dir\": \"data\",\n",
      "    \"fast_read\": false,\n",
      "    \"features_max_len\": 100,\n",
      "    \"image_depth_first\": false,\n",
      "    \"image_features\": {\n",
      "        \"test\": [\n",
      "            \"coco/detectron_fix_100/fc6/train_val_2014\"\n",
      "        ],\n",
      "        \"train\": [\n",
      "            \"coco/detectron_fix_100/fc6/train_val_2014\"\n",
      "        ],\n",
      "        \"val\": [\n",
      "            \"coco/detectron_fix_100/fc6/train_val_2014\"\n",
      "        ]\n",
      "    },\n",
      "    \"imdb_files\": {\n",
      "        \"test\": [\n",
      "            \"imdb/coco_captions/imdb_karpathy_test.npy\"\n",
      "        ],\n",
      "        \"train\": [\n",
      "            \"imdb/coco_captions/imdb_karpathy_train.npy\"\n",
      "        ],\n",
      "        \"val\": [\n",
      "            \"imdb/coco_captions/imdb_karpathy_val.npy\"\n",
      "        ]\n",
      "    },\n",
      "    \"min_captions_per_img\": 5,\n",
      "    \"processors\": {\n",
      "        \"caption_processor\": {\n",
      "            \"params\": {\n",
      "                \"vocab\": {\n",
      "                    \"embedding_name\": \"glove.6B.300d\",\n",
      "                    \"type\": \"intersected\",\n",
      "                    \"vocab_file\": \"vocabs/vocabulary_captioning_thresh5.txt\"\n",
      "                }\n",
      "            },\n",
      "            \"type\": \"caption\"\n",
      "        },\n",
      "        \"text_processor\": {\n",
      "            \"params\": {\n",
      "                \"max_length\": 52,\n",
      "                \"preprocessor\": {\n",
      "                    \"params\": {},\n",
      "                    \"type\": \"simple_sentence\"\n",
      "                },\n",
      "                \"vocab\": {\n",
      "                    \"embedding_name\": \"glove.6B.300d\",\n",
      "                    \"type\": \"intersected\",\n",
      "                    \"vocab_file\": \"vocabs/vocabulary_captioning_thresh5.txt\"\n",
      "                }\n",
      "            },\n",
      "            \"type\": \"vocab\"\n",
      "        }\n",
      "    },\n",
      "    \"return_info\": false,\n",
      "    \"use_ocr\": false,\n",
      "    \"use_ocr_info\": false\n",
      "}\n",
      "2020-03-19T10:43:03 INFO: ======  Optimizer Attributes  ======\n",
      "2020-03-19T10:43:03 INFO: {\n",
      "    \"params\": {\n",
      "        \"eps\": 1e-08,\n",
      "        \"lr\": 0.01,\n",
      "        \"weight_decay\": 0\n",
      "    },\n",
      "    \"type\": \"Adamax\"\n",
      "}\n",
      "2020-03-19T10:43:03 INFO: ======  Model (butd) Attributes  ======\n",
      "2020-03-19T10:43:03 INFO: {\n",
      "    \"classifier\": {\n",
      "        \"params\": {\n",
      "            \"dropout\": 0.5,\n",
      "            \"fc_bias_init\": 0,\n",
      "            \"feature_dim\": 2048,\n",
      "            \"hidden_dim\": 1024\n",
      "        },\n",
      "        \"type\": \"language_decoder\"\n",
      "    },\n",
      "    \"embedding_dim\": 300,\n",
      "    \"image_feature_dim\": 2048,\n",
      "    \"image_feature_embeddings\": [\n",
      "        {\n",
      "            \"modal_combine\": {\n",
      "                \"params\": {\n",
      "                    \"attention_dim\": 1024,\n",
      "                    \"dropout\": 0.5,\n",
      "                    \"hidden_dim\": 1024\n",
      "                },\n",
      "                \"type\": \"top_down_attention_lstm\"\n",
      "            },\n",
      "            \"normalization\": \"softmax\",\n",
      "            \"transform\": {\n",
      "                \"params\": {\n",
      "                    \"out_dim\": 1\n",
      "                },\n",
      "                \"type\": \"linear\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"image_feature_encodings\": [\n",
      "        {\n",
      "            \"params\": {\n",
      "                \"bias_file\": \"detectron/fc6/fc7_b.pkl\",\n",
      "                \"weights_file\": \"detectron/fc6/fc7_w.pkl\"\n",
      "            },\n",
      "            \"type\": \"finetune_faster_rcnn_fpn_fc7\"\n",
      "        }\n",
      "    ],\n",
      "    \"inference\": {\n",
      "        \"type\": \"greedy\"\n",
      "    },\n",
      "    \"losses\": [\n",
      "        {\n",
      "            \"type\": \"caption_cross_entropy\"\n",
      "        }\n",
      "    ],\n",
      "    \"metrics\": [\n",
      "        {\n",
      "            \"type\": \"caption_bleu4\"\n",
      "        }\n",
      "    ],\n",
      "    \"model_data_dir\": \"data/\"\n",
      "}\n",
      "2020-03-19T10:43:03 INFO: Loading tasks and data\n",
      "[Error] captioning not present in our mapping\n",
      "[Error] captioning not present in our mapping\n",
      "[Error] captioning not present in our mapping\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-150b8dea2a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/trainers/base_trainer.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_based_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/trainers/base_trainer.py\u001b[0m in \u001b[0;36mload_task\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/common/task_loader.py\u001b[0m in \u001b[0;36mmake_dataloaders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBatchCollator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         )\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/miniconda3/envs/vqa/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/miniconda3/envs/vqa/lib/python3.6/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m---> 66\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "trainer.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': Namespace(batch_size=None, clip_gradients=None, config='configs/captioning/coco/my_butd_local.yml', config_override=None, config_overwrite=None, data_parallel=None, datasets='coco', device=None, distributed=None, evalai_inference=None, experiment_name=None, fast_read=None, force_restart=False, load_pretrained=None, local_rank=None, log_dir=None, log_interval=None, logger_level=None, lr_scheduler=None, max_epochs=None, max_iterations=None, model='butd', num_workers=None, opts=[], patience=None, resume=None, resume_file=None, run_type=None, save_dir='./save', seed=None, should_not_log=False, snapshot_interval=None, tasks='captioning', verbose_dump=None),\n",
      " 'config': {'datasets': 'coco',\n",
      "            'model': 'butd',\n",
      "            'model_attributes': {'butd': {'classifier': {'params': {'dropout': 0.5,\n",
      "                                                                    'fc_bias_init': 0,\n",
      "                                                                    'feature_dim': 2048,\n",
      "                                                                    'hidden_dim': 1024},\n",
      "                                                         'type': 'language_decoder'},\n",
      "                                          'embedding_dim': 300,\n",
      "                                          'image_feature_dim': 2048,\n",
      "                                          'image_feature_embeddings': [{'modal_combine': {'params': {'attention_dim': 1024,\n",
      "                                                                                                     'dropout': 0.5,\n",
      "                                                                                                     'hidden_dim': 1024},\n",
      "                                                                                          'type': 'top_down_attention_lstm'},\n",
      "                                                                        'normalization': 'softmax',\n",
      "                                                                        'transform': {'params': {'out_dim': 1},\n",
      "                                                                                      'type': 'linear'}}],\n",
      "                                          'image_feature_encodings': [{'params': {'bias_file': 'detectron/fc6/fc7_b.pkl',\n",
      "                                                                                  'weights_file': 'detectron/fc6/fc7_w.pkl'},\n",
      "                                                                       'type': 'finetune_faster_rcnn_fpn_fc7'}],\n",
      "                                          'inference': {'type': 'greedy'},\n",
      "                                          'losses': [{'type': 'caption_cross_entropy'}],\n",
      "                                          'metrics': [{'type': 'caption_bleu4'}],\n",
      "                                          'model_data_dir': 'data/'}},\n",
      "            'optimizer_attributes': {'params': {'eps': 1e-08,\n",
      "                                                'lr': 0.01,\n",
      "                                                'weight_decay': 0},\n",
      "                                     'type': 'Adamax'},\n",
      "            'task_attributes': {'captioning': {'dataset_attributes': {'coco': {'data_root_dir': 'data',\n",
      "                                                                               'fast_read': False,\n",
      "                                                                               'features_max_len': 100,\n",
      "                                                                               'image_depth_first': False,\n",
      "                                                                               'image_features': {'test': ['coco/detectron_fix_100/fc6/train_val_2014'],\n",
      "                                                                                                  'train': ['coco/detectron_fix_100/fc6/train_val_2014'],\n",
      "                                                                                                  'val': ['coco/detectron_fix_100/fc6/train_val_2014']},\n",
      "                                                                               'imdb_files': {'test': ['imdb/coco_captions/imdb_karpathy_test.npy'],\n",
      "                                                                                              'train': ['imdb/coco_captions/imdb_karpathy_train.npy'],\n",
      "                                                                                              'val': ['imdb/coco_captions/imdb_karpathy_val.npy']},\n",
      "                                                                               'min_captions_per_img': 5,\n",
      "                                                                               'processors': {'caption_processor': {'params': {'vocab': {'embedding_name': 'glove.6B.300d',\n",
      "                                                                                                                                         'type': 'intersected',\n",
      "                                                                                                                                         'vocab_file': 'vocabs/vocabulary_captioning_thresh5.txt'}},\n",
      "                                                                                                                    'type': 'caption'},\n",
      "                                                                                              'text_processor': {'params': {'max_length': 52,\n",
      "                                                                                                                            'preprocessor': {'params': {},\n",
      "                                                                                                                                             'type': 'simple_sentence'},\n",
      "                                                                                                                            'vocab': {'embedding_name': 'glove.6B.300d',\n",
      "                                                                                                                                      'type': 'intersected',\n",
      "                                                                                                                                      'vocab_file': 'vocabs/vocabulary_captioning_thresh5.txt'}},\n",
      "                                                                                                                 'type': 'vocab'}},\n",
      "                                                                               'return_info': False,\n",
      "                                                                               'use_ocr': False,\n",
      "                                                                               'use_ocr_info': False}},\n",
      "                                               'dataset_size_proportional_sampling': True,\n",
      "                                               'datasets': 'coco'}},\n",
      "            'tasks': 'captioning',\n",
      "            'training_parameters': {'batch_size': 2,\n",
      "                                    'clip_gradients': True,\n",
      "                                    'clip_norm_mode': 'all',\n",
      "                                    'data_parallel': True,\n",
      "                                    'device': 'cuda',\n",
      "                                    'distributed': False,\n",
      "                                    'evalai_inference': False,\n",
      "                                    'experiment_name': 'run',\n",
      "                                    'load_pretrained': False,\n",
      "                                    'local_rank': None,\n",
      "                                    'log_dir': './logs',\n",
      "                                    'log_interval': 100,\n",
      "                                    'logger_level': 'info',\n",
      "                                    'lr_ratio': 0.1,\n",
      "                                    'lr_scheduler': True,\n",
      "                                    'lr_steps': [1, 1, 1, 1],\n",
      "                                    'max_epochs': None,\n",
      "                                    'max_grad_l2_norm': 0.25,\n",
      "                                    'max_iterations': 1,\n",
      "                                    'metric_minimize': False,\n",
      "                                    'monitored_metric': 'caption_bleu4',\n",
      "                                    'num_workers': 0,\n",
      "                                    'patience': 1,\n",
      "                                    'pin_memory': False,\n",
      "                                    'pretrained_mapping': {},\n",
      "                                    'resume': False,\n",
      "                                    'resume_file': None,\n",
      "                                    'run_type': 'train+inference',\n",
      "                                    'save_dir': './save',\n",
      "                                    'seed': None,\n",
      "                                    'should_early_stop': False,\n",
      "                                    'should_not_log': False,\n",
      "                                    'snapshot_interval': 1000,\n",
      "                                    'task_size_proportional_sampling': True,\n",
      "                                    'trainer': 'base_trainer',\n",
      "                                    'use_warmup': True,\n",
      "                                    'verbose_dump': False,\n",
      "                                    'warmup_factor': 0.2,\n",
      "                                    'warmup_iterations': 1000}},\n",
      " 'configuration': <pythia.utils.configuration.Configuration object at 0x7f59b0066278>,\n",
      " 'device': 'cuda',\n",
      " 'local_rank': None,\n",
      " 'profiler': <pythia.utils.timer.Timer object at 0x7f59988607b8>,\n",
      " 'run_type': 'train+inference',\n",
      " 'task_loader': <pythia.common.task_loader.TaskLoader object at 0x7f5998860710>,\n",
      " 'writer': <pythia.utils.logger.Logger object at 0x7f59988605f8>}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(trainer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer.train()\n",
    "\n",
    "```python\n",
    "    def train(self):\n",
    "        self.writer.write(\"===== Model =====\")\n",
    "        self.writer.write(self.model)\n",
    "\n",
    "        if \"train\" not in self.run_type:\n",
    "            self.inference()\n",
    "            return\n",
    "\n",
    "        should_break = False\n",
    "\n",
    "        if self.max_epochs is None:\n",
    "            self.max_epochs = math.inf\n",
    "        else:\n",
    "            self.max_iterations = math.inf\n",
    "\n",
    "        self.model.train()\n",
    "        self.train_timer = Timer()\n",
    "        self.snapshot_timer = Timer()\n",
    "\n",
    "        self.profile(\"Setup Time\")\n",
    "\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "        self.writer.write(\"Starting training...\")\n",
    "        while self.current_iteration < self.max_iterations and not should_break:\n",
    "            self.current_epoch += 1\n",
    "            registry.register(\"current_epoch\", self.current_epoch)\n",
    "\n",
    "            # Seed the sampler in case if it is distributed\n",
    "            self.task_loader.seed_sampler(\"train\", self.current_epoch)\n",
    "\n",
    "            if self.current_epoch > self.max_epochs:\n",
    "                break\n",
    "\n",
    "            for batch in self.train_loader:\n",
    "                self.profile(\"Batch load time\")\n",
    "                self.current_iteration += 1\n",
    "                self.writer.write(self.current_iteration, \"debug\")\n",
    "\n",
    "                registry.register(\"current_iteration\", self.current_iteration)\n",
    "\n",
    "                if self.current_iteration > self.max_iterations:\n",
    "                    break\n",
    "\n",
    "                self._run_scheduler()\n",
    "                report = self._forward_pass(batch)\n",
    "                self._update_meter(report, self.meter)\n",
    "                loss = self._extract_loss(report)\n",
    "                self._backward(loss)\n",
    "                should_break = self._logistics(report)\n",
    "\n",
    "                if should_break:\n",
    "                    break\n",
    "\n",
    "        self.finalize()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseTrainer' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b1bb82f8df85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseTrainer' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainer.inference()\n",
    "\n",
    "```python\n",
    "def inference(self):\n",
    "    if \"val\" in self.run_type:\n",
    "        self._inference_run(\"val\")\n",
    "\n",
    "    if \"inference\" in self.run_type or \"predict\" in self.run_type:\n",
    "        self._inference_run(\"test\")\n",
    "        \n",
    "def _inference_run(self, dataset_type):\n",
    "    if self.config.training_parameters.evalai_inference is True:\n",
    "        self.predict_for_evalai(dataset_type)\n",
    "        return\n",
    "\n",
    "    self.writer.write(\"Starting inference on {} set\".format(dataset_type))\n",
    "\n",
    "    report, meter = self.evaluate(\n",
    "        getattr(self, \"{}_loader\".format(dataset_type)), use_tqdm=True\n",
    "    )\n",
    "    prefix = \"{}: full {}\".format(report.dataset_name, dataset_type)\n",
    "    self._summarize_report(meter, prefix)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-19T10:42:28 INFO: Starting inference on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/2500 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tf/notebooks/jwhwang/vqa/pythia/pythia/data/coco/detectron_fix_100/fc6/train_val_2014/COCO_val2014_000000060623.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-267cb1d0e195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/trainers/base_trainer.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"inference\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_type\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"predict\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_inference_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/trainers/base_trainer.py\u001b[0m in \u001b[0;36m_inference_run\u001b[0;34m(self, dataset_type)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         report, meter = self.evaluate(\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{}_loader\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         )\n\u001b[1;32m    440\u001b[0m         \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}: full {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/trainers/base_trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, loader, use_tqdm, single_batch)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0muse_tqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m                 \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_meter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/miniconda3/envs/vqa/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/miniconda3/envs/vqa/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/miniconda3/envs/vqa/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/multi_task.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_lens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_task\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchosen_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/base_task.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_dataset_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_choice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchosen_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/miniconda3/envs/vqa/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/base_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mDO\u001b[0m \u001b[0mNOT\u001b[0m \u001b[0mOVERRIDE\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mInstead\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mget_item\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/vqa/vqa2/dataset.py\u001b[0m in \u001b[0;36mget_item\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/captioning/coco/dataset.py\u001b[0m in \u001b[0;36mload_item\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_db\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mcurrent_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/features_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_db\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/features_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mimage_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}.npy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mimage_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_image_features_and_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/features_dataset.py\u001b[0m in \u001b[0;36m_get_image_features_and_info\u001b[0;34m(self, feat_file)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage_feats\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mimage_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_features_and_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# TODO: Remove after standardization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/features_dataset.py\u001b[0m in \u001b[0;36m_read_features_and_info\u001b[0;34m(self, feat_file)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature_reader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_readers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;31m# feature = torch.from_numpy(feature).share_memory_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/feature_readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, image_feat_path)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_feat_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/jwhwang/vqa/pythia/pythia/tasks/feature_readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, image_feat_path)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_feat_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_feat_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0minfo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}_info.npy\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_feat_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mimage_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tf/notebooks/miniconda3/envs/vqa/lib/python3.6/site-packages/numpy-1.18.1-py3.6-linux-x86_64.egg/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tf/notebooks/jwhwang/vqa/pythia/pythia/data/coco/detectron_fix_100/fc6/train_val_2014/COCO_val2014_000000060623.npy'"
     ]
    }
   ],
   "source": [
    "trainer.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "vqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
